{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# Wine Quality Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "Are you an expert in Wine Tasting?\n",
    "\n",
    "You or your ‚ÄúComputer‚Äù, Which of you is better in recognizing a wine quality?üç∑\n",
    "\n",
    "Build a model to learn from a dataset, recorded by the world's top wine experts, and become an expert in wine quality!ü•É üç∏ üçπ\n",
    "\n",
    "ü•Ç<font color=green> Fun fact: wine testing is a common thought experiment used by philosophers who do not believe in strong AI. Let's try though, and see if an AI can learn the art of wines!\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('WineData.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Note:<br>\n",
    "<font color='black'> Several world's wine experts labaled several red wines as:<br>\n",
    "    - Grade 1: High Quality <br>\n",
    "    - Grade 2: Medium Qulaity <br>\n",
    "    - Grade 3: Poor Quality <br>\n",
    "\n",
    "    The chemical components (13 features) of each of these wines have been then measured and summarized WineData.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Expert_Opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>High Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>High Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>High Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>High Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>High Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "      <td>Poor Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "      <td>Poor Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "      <td>Poor Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "      <td>Poor Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "      <td>Poor Quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "0      14.23        1.71  2.43          15.6        127           2.80   \n",
       "1      13.20        1.78  2.14          11.2        100           2.65   \n",
       "2      13.16        2.36  2.67          18.6        101           2.80   \n",
       "3      14.37        1.95  2.50          16.8        113           3.85   \n",
       "4      13.24        2.59  2.87          21.0        118           2.80   \n",
       "..       ...         ...   ...           ...        ...            ...   \n",
       "173    13.71        5.65  2.45          20.5         95           1.68   \n",
       "174    13.40        3.91  2.48          23.0        102           1.80   \n",
       "175    13.27        4.28  2.26          20.0        120           1.59   \n",
       "176    13.17        2.59  2.37          20.0        120           1.65   \n",
       "177    14.13        4.10  2.74          24.5         96           2.05   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     OD280  Proline Expert_Opinion  \n",
       "0     3.92     1065   High Quality  \n",
       "1     3.40     1050   High Quality  \n",
       "2     3.17     1185   High Quality  \n",
       "3     3.45     1480   High Quality  \n",
       "4     2.93      735   High Quality  \n",
       "..     ...      ...            ...  \n",
       "173   1.74      740   Poor Quality  \n",
       "174   1.56      750   Poor Quality  \n",
       "175   1.56      835   Poor Quality  \n",
       "176   1.62      840   Poor Quality  \n",
       "177   1.60      560   Poor Quality  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Output Data\n",
    "Here, we replace High, Medium, and Poor Qulaity with Labels 0,1, and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the Dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Building the ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "WineModel=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "WineModel.add(tf.keras.layers.Dense(13,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the First Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "WineModel.add(tf.keras.layers.Dense(6,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Second, Third, ... Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only add extra layers if we need to, in order to increase the accuracy;\n",
    "# we just need to repeat the same line of code, maybe with different or same \n",
    "# number of nodes.\n",
    "\n",
    "#WineModel.add(tf.keras.layers.Dense(6,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "WineModel.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
    "# Note, you have 3 classes, so, you change this number accordingly.\n",
    "# You may try differnt activation function; like 'softmax' or 'sigmoid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN\n",
    "<font color=red> Note: <font color=blue> Here you can try two differnt optimizers algorithms, such as : <br>\n",
    "    - 'adam'<br>\n",
    "    - 'sgd' <br>\n",
    "To calculate Error/loss, you may use any criteria, such as: <br>\n",
    "    - 'mean_squared_error'<br>\n",
    "    - 'sparse_categorical_crossentropy'<br>\n",
    "And, for measuring the accuracy, you can use:<br>\n",
    "    - 'accuracy'<br>\n",
    "    \n",
    "Extra things to know:<br>\n",
    "Cross entropy is a loss function, used to measure the dissimilarity between the distribution of observed class labels and the predicted probabilities of class membership.<br> \n",
    "That is the categorical cross entropy. Sparse means that it does use all the possible classes but some of them. This is useful when you have a lot of classes (like 1000) where softmax would be a very slow function to calculate among all of them. So you basically select some of those 1000 classes and apply the categorical cross entropy.<br>\n",
    "    \n",
    "Interested in learning more:<br>\n",
    "Loss and Loss Functions for Training Deep Learning Neural Networks: <br>\n",
    "    https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/ <br>\n",
    "How to Choose Loss Functions When Training Deep Learning Neural Networks:<br>\n",
    "https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "WineModel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Training the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4780 - accuracy: 0.1056\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4072 - accuracy: 0.1408\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3454 - accuracy: 0.1408\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2930 - accuracy: 0.1620\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2499 - accuracy: 0.1972\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2108 - accuracy: 0.2465\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1773 - accuracy: 0.2817\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1446 - accuracy: 0.3380\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1163 - accuracy: 0.3662\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0846 - accuracy: 0.4225\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0553 - accuracy: 0.4648\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0239 - accuracy: 0.5211\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9931 - accuracy: 0.5352\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9608 - accuracy: 0.5986\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9295 - accuracy: 0.6268\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9008 - accuracy: 0.6549\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8726 - accuracy: 0.6901\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8442 - accuracy: 0.7324\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8167 - accuracy: 0.7535\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7943 - accuracy: 0.7746\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7701 - accuracy: 0.7746\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.7817\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7259 - accuracy: 0.8099\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.8451\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.8592\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.8662\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.8803\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6093 - accuracy: 0.9085\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.9155\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.9296\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.9296\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.9437\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.9507\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.9507\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.9577\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.9648\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.9648\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.9648\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.9718\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.9718\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.9718\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.9718\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.9718\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.9718\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2518 - accuracy: 0.9718\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9718\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9718\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9789\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2021 - accuracy: 0.9789\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9789\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9789\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9789\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9789\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9789\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9789\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9789\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9789\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9789\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9789\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9789\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1153 - accuracy: 0.9789\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9859\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.9859\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9859\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9859\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9859\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9859\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0886 - accuracy: 0.9859\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9930\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9930\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9930\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9930\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9930\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9930\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9930\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9930\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9930\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9930\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9930\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9930\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9930\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9930\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9930\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9930\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9930\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9930\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9930\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9930\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9930\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0490 - accuracy: 0.9930\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9930\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9930\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9930\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9930\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9930\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9930\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9930\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9930\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9930\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x202dc43fd90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WineModel.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of each class [0.43444905 0.5466901  0.01886084]\n",
      "The actual Class 0\n"
     ]
    }
   ],
   "source": [
    "y_pred = WineModel.predict(X_test)\n",
    "\n",
    "# let's just do some quick checking: \n",
    "print(\"The probability of each class\",y_pred[12])\n",
    "print(\"The actual Class\", y_test[12])\n",
    "\n",
    "# Recall, Actual Classes are: 0 (High Quality), 1 (Medium), 2 (Por)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.616732656955719, 0.5833333134651184]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WineModel.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhU1LTgPg-kH"
   },
   "source": [
    "##### <font color='red'> Let's make some new wine and get the expert's opinion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of your wine belongs to High Qulaity class is [43.444904]\n",
      "Chance of your wine belongs to Medium Qulaity class is [54.66901]\n",
      "Chance of your wine belongs to Poor Qulaity class is [1.8860843]\n"
     ]
    }
   ],
   "source": [
    "# Assume you made a wine and here are the 13 chemical components:\n",
    "PredictQuality=WineModel.predict(sc.transform([[14.23,1.71,2.43,15.6,127.0,2.80,3.06,0.28,2.29,5.64,1.04,3.92,1065.0]]))\n",
    "print(\"Chance of your wine belongs to High Qulaity class is\",PredictQuality[:,0]*100)\n",
    "print(\"Chance of your wine belongs to Medium Qulaity class is\",PredictQuality[:,1]*100)\n",
    "print(\"Chance of your wine belongs to Poor Qulaity class is\",PredictQuality[:,2]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='magenta'> You may make your code nicer by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2d8IoCCkeWGL",
    "outputId": "957f3970-e197-4c3b-a150-7f69dc567f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be disappointed, You may be able to improve yourwine, it is Grade 2 Medium Qulaity Wine\n"
     ]
    }
   ],
   "source": [
    "Your_Wine=np.max(PredictQuality)\n",
    "if Your_Wine==PredictQuality[:,0]:\n",
    "    print(\"Congratulation, You have Grade 1 High Qulaity Wine\")\n",
    "elif Your_Wine==PredictQuality[:,1]:\n",
    "    print(\"Don't be disappointed, You may be able to improve yourwine, it is Grade 2 Medium Qulaity Wine\")\n",
    "else:\n",
    "    print(\"Sorry, you produce a poor quality, grade 3 wine!\")\n",
    "\n",
    "    \n",
    "#if Bonus_Status>0.5:\n",
    "    #print (\"This employee gets the bonus. :)\")\n",
    "#else:\n",
    "    #print (\"This employee does not get the bonus. :(\")\n",
    "#PredictQuality[:,0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "124e47c1ad6ceb91c3ceb1dde65cfb37b91587009ebc216d439d411f4704dda1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
