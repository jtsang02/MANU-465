{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37puETfgRzzg"
   },
   "source": [
    "# Assignment 4. Semiconductor Manufacturer, Artificial Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "This project builds an Artificial Neural Network (ANN) model to predict whether a manufactured part passes or fails.\n",
    "\n",
    "\n",
    "Source: https://www.kaggle.com/saurabhbagchi/fmst-semiconductor-manufacturing-project\n",
    "\n",
    "A complex modern semiconductor manufacturing process is normally under constant surveillance via the monitoring of signals/variables collected from sensors and or process measurement points. However, not all of these signals are equally valuable in a specific monitoring system. The measured signals contain a combination of useful information, irrelevant information as well as noise. Engineers typically have a much larger number of signals than are actually required. If we consider each type of signal as a feature, then feature selection may be applied to identify the most relevant signals. The Process Engineers may then use these signals to determine key factors contributing to yield excursions downstream in the process. This will enable an increase in process throughput, decreased time to learning, and reduce per-unit production costs. These signals can be used as features to predict the yield type. And by analyzing and trying out different combinations of features, essential signals that are impacting the yield type can be identified.\n",
    "\n",
    "Dataset: SemiconductorManufacturingProcessDataset.csv (on Canvas)\n",
    "\n",
    "Later, we will learn how to apply PCA (Principal Component Analyses) for feature selection; then we will apply ANN to predict the Pass/Fail. in this exercise our objective is to repeat the same steps we did above for Supplier Data: Cleaning & Scaling Data, Encode Categorical Data, Split the Data to Training & Test Sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwEPNDWySTKm"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('SemiconductorManufacturingProcessDataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing the Dataset in a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Sensor 1</th>\n",
       "      <th>Sensor 2</th>\n",
       "      <th>Sensor 3</th>\n",
       "      <th>Sensor 4</th>\n",
       "      <th>Sensor 5</th>\n",
       "      <th>Sensor 6</th>\n",
       "      <th>Sensor 7</th>\n",
       "      <th>Sensor 8</th>\n",
       "      <th>Sensor 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor 429</th>\n",
       "      <th>Sensor 430</th>\n",
       "      <th>Sensor 431</th>\n",
       "      <th>Sensor 432</th>\n",
       "      <th>Sensor 433</th>\n",
       "      <th>Sensor 434</th>\n",
       "      <th>Sensor 435</th>\n",
       "      <th>Sensor 436</th>\n",
       "      <th>Sensor 437</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/19/2008 11:55</td>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9509</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/19/2008 12:32</td>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9003</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/19/2008 13:17</td>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>9.2721</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/19/2008 14:43</td>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5831</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/19/2008 15:22</td>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9698</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>10/16/2008 15:13</td>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7256</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>10/16/2008 20:49</td>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8379</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>10/17/2008 5:26</td>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17.7267</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>10/17/2008 6:01</td>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>19.2104</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>10/17/2008 6:07</td>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.9183</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time  Sensor 1  Sensor 2   Sensor 3   Sensor 4  Sensor 5  \\\n",
       "0      7/19/2008 11:55   3030.93   2564.00  2187.7333  1411.1265    1.3602   \n",
       "1      7/19/2008 12:32   3095.78   2465.14  2230.4222  1463.6606    0.8294   \n",
       "2      7/19/2008 13:17   2932.61   2559.94  2186.4111  1698.0172    1.5102   \n",
       "3      7/19/2008 14:43   2988.72   2479.90  2199.0333   909.7926    1.3204   \n",
       "4      7/19/2008 15:22   3032.24   2502.87  2233.3667  1326.5200    1.5334   \n",
       "...                ...       ...       ...        ...        ...       ...   \n",
       "1562  10/16/2008 15:13   2899.41   2464.36  2179.7333  3085.3781    1.4843   \n",
       "1563  10/16/2008 20:49   3052.31   2522.55  2198.5667  1124.6595    0.8763   \n",
       "1564   10/17/2008 5:26   2978.81   2379.78  2206.3000  1110.4967    0.8236   \n",
       "1565   10/17/2008 6:01   2894.92   2532.01  2177.0333  1183.7287    1.5726   \n",
       "1566   10/17/2008 6:07   2944.92   2450.76  2195.4444  2914.1792    1.5978   \n",
       "\n",
       "      Sensor 6  Sensor 7  Sensor 8  Sensor 9  ...  Sensor 429  Sensor 430  \\\n",
       "0      97.6133    0.1242    1.5005    0.0162  ...     14.9509      0.5005   \n",
       "1     102.3433    0.1247    1.4966   -0.0005  ...     10.9003      0.5019   \n",
       "2      95.4878    0.1241    1.4436    0.0041  ...      9.2721      0.4958   \n",
       "3     104.2367    0.1217    1.4882   -0.0124  ...      8.5831      0.4990   \n",
       "4     100.3967    0.1235    1.5031   -0.0031  ...     10.9698      0.4800   \n",
       "...        ...       ...       ...       ...  ...         ...         ...   \n",
       "1562   82.2467    0.1248    1.3424   -0.0045  ...     11.7256      0.4988   \n",
       "1563   98.4689    0.1205    1.4333   -0.0061  ...     17.8379      0.4975   \n",
       "1564   99.4122    0.1208       NaN       NaN  ...     17.7267      0.4987   \n",
       "1565   98.7978    0.1213    1.4622   -0.0072  ...     19.2104      0.5004   \n",
       "1566   85.1011    0.1235       NaN       NaN  ...     22.9183      0.4987   \n",
       "\n",
       "      Sensor 431  Sensor 432  Sensor 433  Sensor 434  Sensor 435  Sensor 436  \\\n",
       "0         0.0118      0.0035      2.3630         NaN         NaN         NaN   \n",
       "1         0.0223      0.0055      4.4447      0.0096      0.0201      0.0060   \n",
       "2         0.0157      0.0039      3.1745      0.0584      0.0484      0.0148   \n",
       "3         0.0103      0.0025      2.0544      0.0202      0.0149      0.0044   \n",
       "4         0.4766      0.1045     99.3032      0.0202      0.0149      0.0044   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1562      0.0143      0.0039      2.8669      0.0068      0.0138      0.0047   \n",
       "1563      0.0131      0.0036      2.6238      0.0068      0.0138      0.0047   \n",
       "1564      0.0153      0.0041      3.0590      0.0197      0.0086      0.0025   \n",
       "1565      0.0178      0.0038      3.5662      0.0262      0.0245      0.0075   \n",
       "1566      0.0181      0.0040      3.6275      0.0117      0.0162      0.0045   \n",
       "\n",
       "      Sensor 437  Pass/Fail  \n",
       "0            NaN       Pass  \n",
       "1       208.2045       Pass  \n",
       "2        82.8602       Fail  \n",
       "3        73.8432       Pass  \n",
       "4        73.8432       Pass  \n",
       "...          ...        ...  \n",
       "1562    203.1720       Pass  \n",
       "1563    203.1720       Pass  \n",
       "1564     43.5231       Pass  \n",
       "1565     93.4941       Pass  \n",
       "1566    137.7844       Pass  \n",
       "\n",
       "[1567 rows x 439 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset)\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Review of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Columns: 439 entries, Time to Pass/Fail\n",
      "dtypes: float64(437), object(2)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate The Input and Output\n",
    "Here, we put the independent variables in X and the dependent variable in y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:438].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing the Input Data in a Table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "hCsz2yCebe1R",
    "outputId": "1e4cc568-4e51-4b38-9d46-4aa3f15204be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "      <th>431</th>\n",
       "      <th>432</th>\n",
       "      <th>433</th>\n",
       "      <th>434</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6765</td>\n",
       "      <td>14.9509</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1065</td>\n",
       "      <td>10.9003</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0952</td>\n",
       "      <td>9.2721</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>8.5831</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6597</td>\n",
       "      <td>10.9698</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4879</td>\n",
       "      <td>11.7256</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0187</td>\n",
       "      <td>17.8379</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2237</td>\n",
       "      <td>17.7267</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7085</td>\n",
       "      <td>19.2104</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2878</td>\n",
       "      <td>22.9183</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1          2          3       4         5       6    \\\n",
       "0     3030.93  2564.00  2187.7333  1411.1265  1.3602   97.6133  0.1242   \n",
       "1     3095.78  2465.14  2230.4222  1463.6606  0.8294  102.3433  0.1247   \n",
       "2     2932.61  2559.94  2186.4111  1698.0172  1.5102   95.4878  0.1241   \n",
       "3     2988.72  2479.90  2199.0333   909.7926  1.3204  104.2367  0.1217   \n",
       "4     3032.24  2502.87  2233.3667  1326.5200  1.5334  100.3967  0.1235   \n",
       "...       ...      ...        ...        ...     ...       ...     ...   \n",
       "1562  2899.41  2464.36  2179.7333  3085.3781  1.4843   82.2467  0.1248   \n",
       "1563  3052.31  2522.55  2198.5667  1124.6595  0.8763   98.4689  0.1205   \n",
       "1564  2978.81  2379.78  2206.3000  1110.4967  0.8236   99.4122  0.1208   \n",
       "1565  2894.92  2532.01  2177.0333  1183.7287  1.5726   98.7978  0.1213   \n",
       "1566  2944.92  2450.76  2195.4444  2914.1792  1.5978   85.1011  0.1235   \n",
       "\n",
       "         7       8       9    ...     427      428     429     430     431  \\\n",
       "0     1.5005  0.0162 -0.0034  ...  1.6765  14.9509  0.5005  0.0118  0.0035   \n",
       "1     1.4966 -0.0005 -0.0148  ...  1.1065  10.9003  0.5019  0.0223  0.0055   \n",
       "2     1.4436  0.0041  0.0013  ...  2.0952   9.2721  0.4958  0.0157  0.0039   \n",
       "3     1.4882 -0.0124 -0.0033  ...  1.7585   8.5831  0.4990  0.0103  0.0025   \n",
       "4     1.5031 -0.0031 -0.0072  ...  1.6597  10.9698  0.4800  0.4766  0.1045   \n",
       "...      ...     ...     ...  ...     ...      ...     ...     ...     ...   \n",
       "1562  1.3424 -0.0045 -0.0057  ...  1.4879  11.7256  0.4988  0.0143  0.0039   \n",
       "1563  1.4333 -0.0061 -0.0093  ...  1.0187  17.8379  0.4975  0.0131  0.0036   \n",
       "1564     NaN     NaN     NaN  ...  1.2237  17.7267  0.4987  0.0153  0.0041   \n",
       "1565  1.4622 -0.0072  0.0032  ...  1.7085  19.2104  0.5004  0.0178  0.0038   \n",
       "1566     NaN     NaN     NaN  ...  1.2878  22.9183  0.4987  0.0181  0.0040   \n",
       "\n",
       "          432     433     434     435       436  \n",
       "0      2.3630     NaN     NaN     NaN       NaN  \n",
       "1      4.4447  0.0096  0.0201  0.0060  208.2045  \n",
       "2      3.1745  0.0584  0.0484  0.0148   82.8602  \n",
       "3      2.0544  0.0202  0.0149  0.0044   73.8432  \n",
       "4     99.3032  0.0202  0.0149  0.0044   73.8432  \n",
       "...       ...     ...     ...     ...       ...  \n",
       "1562   2.8669  0.0068  0.0138  0.0047  203.1720  \n",
       "1563   2.6238  0.0068  0.0138  0.0047  203.1720  \n",
       "1564   3.0590  0.0197  0.0086  0.0025   43.5231  \n",
       "1565   3.5662  0.0262  0.0245  0.0075   93.4941  \n",
       "1566   3.6275  0.0117  0.0162  0.0045  137.7844  \n",
       "\n",
       "[1567 rows x 437 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Check of the Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eYrOQ43XcJR3",
    "outputId": "e0873b2a-3b08-4bab-ef0d-15b88858ca44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0     Pass\n",
       "1     Pass\n",
       "2     Fail\n",
       "3     Pass\n",
       "4     Pass\n",
       "...    ...\n",
       "1562  Pass\n",
       "1563  Pass\n",
       "1564  Pass\n",
       "1565  Pass\n",
       "1566  Pass\n",
       "\n",
       "[1567 rows x 1 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhfKXNxlSabC"
   },
   "source": [
    "## Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c93k7ipkSexq"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X)\n",
    "X = imputer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "3UgLdMS_bjq_",
    "outputId": "254af4e0-681e-47f5-aaa7-b9c6f43258e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.03093000e+03 2.56400000e+03 2.18773330e+03 ... 1.64749042e-02\n",
      "  5.28333333e-03 9.96700663e+01]\n",
      " [3.09578000e+03 2.46514000e+03 2.23042220e+03 ... 2.01000000e-02\n",
      "  6.00000000e-03 2.08204500e+02]\n",
      " [2.93261000e+03 2.55994000e+03 2.18641110e+03 ... 4.84000000e-02\n",
      "  1.48000000e-02 8.28602000e+01]\n",
      " ...\n",
      " [2.97881000e+03 2.37978000e+03 2.20630000e+03 ... 8.60000000e-03\n",
      "  2.50000000e-03 4.35231000e+01]\n",
      " [2.89492000e+03 2.53201000e+03 2.17703330e+03 ... 2.45000000e-02\n",
      "  7.50000000e-03 9.34941000e+01]\n",
      " [2.94492000e+03 2.45076000e+03 2.19544440e+03 ... 1.62000000e-02\n",
      "  4.50000000e-03 1.37784400e+02]]\n"
     ]
    }
   ],
   "source": [
    "# A quick check\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CriG6VzVSjcK"
   },
   "source": [
    "## Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhSpdQWeSsFh"
   },
   "source": [
    "### Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hwuVddlSwVi"
   },
   "outputs": [],
   "source": [
    "# we don't have any categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXh8oVSITIc6"
   },
   "source": [
    "### Encoding the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgHCShVyTOYY"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FyhY8-gPpFCa",
    "outputId": "7f76ef29-5423-4c3e-cf69-45fbc366a997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# a qucik check\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpGqbS4TqkIR"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxjSUXFQqo-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qb_vcgm3qZKW"
   },
   "source": [
    "## Splitting the Dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXgA6CzlqbCl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "GuwQhFdKrYTM",
    "outputId": "de1e527f-c229-4daf-e7c5-ea9d2485148d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96046311 -0.73813734 -0.92237938 ... -0.06531583 -0.16868853\n",
      "  -0.2120265 ]\n",
      " [-0.87742151  0.5426257  -0.13250295 ...  0.60499301  0.38972867\n",
      "   3.17408017]\n",
      " [ 0.05645609 -1.51130825  1.47184855 ...  0.04829584  0.04071792\n",
      "   0.42803032]\n",
      " ...\n",
      " [-0.55464836 -0.10473817 -1.25868434 ...  1.9342495   2.16968349\n",
      "   0.21655552]\n",
      " [-0.24467179 -0.00336937 -1.42475658 ... -0.64473532 -0.79690788\n",
      "  -0.64548212]\n",
      " [-0.36283589 -0.07880372  0.55448143 ... -0.19028866 -0.02908423\n",
      "   1.62346601]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "TUrX_Tvcrbi4",
    "outputId": "9a041a9b-2642-4828-fa2f-a431d7d77631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38726113 -0.80185131  0.15916359 ... -0.66745766 -0.65730358\n",
      "  -0.56211928]\n",
      " [-0.02413509 -0.94137368 -0.96134565 ... -1.08782082 -0.86671003\n",
      "  -0.69795783]\n",
      " [ 0.70418053  0.53813704 -0.68064891 ... -0.06531583  0.00581685\n",
      "  -0.30543175]\n",
      " ...\n",
      " [ 0.08504418  0.83962507 -1.23522968 ... -1.12190432 -1.07611647\n",
      "  -0.7688942 ]\n",
      " [ 2.27530028  0.21096393 -0.97685385 ... -0.59929066 -0.55260035\n",
      "  -0.6417691 ]\n",
      " [-0.8523729  -0.23341296 -0.28457524 ... -0.50840133 -0.51769928\n",
      "  -0.33965675]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pSMHiIsWreQY",
    "outputId": "5afe91e0-9244-4bf5-ec1b-e3e092b85c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I_tW7H56rgtW",
    "outputId": "2a93f141-2a99-4a69-eec5-c82a3bb8d36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "DWPET8ZdlMnu",
    "outputId": "dea86927-5124-4e2a-e974-2804df9a913c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96046311 -0.73813734 -0.92237938 ... -0.06531583 -0.16868853\n",
      "  -0.2120265 ]\n",
      " [-0.87742151  0.5426257  -0.13250295 ...  0.60499301  0.38972867\n",
      "   3.17408017]\n",
      " [ 0.05645609 -1.51130825  1.47184855 ...  0.04829584  0.04071792\n",
      "   0.42803032]\n",
      " ...\n",
      " [-0.55464836 -0.10473817 -1.25868434 ...  1.9342495   2.16968349\n",
      "   0.21655552]\n",
      " [-0.24467179 -0.00336937 -1.42475658 ... -0.64473532 -0.79690788\n",
      "  -0.64548212]\n",
      " [-0.36283589 -0.07880372  0.55448143 ... -0.19028866 -0.02908423\n",
      "   1.62346601]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sTXykB_QlRjE",
    "outputId": "b68f0cfc-d07c-48cb-80d0-6800028c41f9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38726113 -0.80185131  0.15916359 ... -0.66745766 -0.65730358\n",
      "  -0.56211928]\n",
      " [-0.02413509 -0.94137368 -0.96134565 ... -1.08782082 -0.86671003\n",
      "  -0.69795783]\n",
      " [ 0.70418053  0.53813704 -0.68064891 ... -0.06531583  0.00581685\n",
      "  -0.30543175]\n",
      " ...\n",
      " [ 0.08504418  0.83962507 -1.23522968 ... -1.12190432 -1.07611647\n",
      "  -0.7688942 ]\n",
      " [ 2.27530028  0.21096393 -0.97685385 ... -0.59929066 -0.55260035\n",
      "  -0.6417691 ]\n",
      " [-0.8523729  -0.23341296 -0.28457524 ... -0.50840133 -0.51769928\n",
      "  -0.33965675]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build input later\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "# build first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=3, activation='relu'))\n",
    "\n",
    "# build output layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 0s 793us/step - loss: 0.1974 - accuracy: 0.9210\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.1802 - accuracy: 0.9346\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 793us/step - loss: 0.1655 - accuracy: 0.9346\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.1527 - accuracy: 0.9346\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.1415 - accuracy: 0.9346\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.1323 - accuracy: 0.9346\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 793us/step - loss: 0.1241 - accuracy: 0.9346\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 742us/step - loss: 0.1170 - accuracy: 0.9346\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.1106 - accuracy: 0.9346\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 742us/step - loss: 0.1049 - accuracy: 0.9346\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.1000 - accuracy: 0.9346\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 742us/step - loss: 0.0956 - accuracy: 0.9346\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 793us/step - loss: 0.0917 - accuracy: 0.9346\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.0881 - accuracy: 0.9346\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.0849 - accuracy: 0.9346\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 793us/step - loss: 0.0821 - accuracy: 0.9346\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.0796 - accuracy: 0.9346\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 742us/step - loss: 0.0775 - accuracy: 0.9346\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.0757 - accuracy: 0.9346\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 742us/step - loss: 0.0740 - accuracy: 0.9346\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.0725 - accuracy: 0.9346\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 818us/step - loss: 0.0711 - accuracy: 0.9346\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.0699 - accuracy: 0.9346\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.0688 - accuracy: 0.9346\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0677 - accuracy: 0.9346\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 844us/step - loss: 0.0667 - accuracy: 0.9346\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0658 - accuracy: 0.9346\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0650 - accuracy: 0.9346\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0643 - accuracy: 0.9346\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0637 - accuracy: 0.9346\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0631 - accuracy: 0.9346\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0625 - accuracy: 0.9346\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0620 - accuracy: 0.9346\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0615 - accuracy: 0.9346\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0611 - accuracy: 0.9346\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0607 - accuracy: 0.9346\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0603 - accuracy: 0.9346\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0600 - accuracy: 0.9346\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0596 - accuracy: 0.9346\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0593 - accuracy: 0.9346\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0590 - accuracy: 0.9346\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0587 - accuracy: 0.9346\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0585 - accuracy: 0.9346\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0582 - accuracy: 0.9346\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0580 - accuracy: 0.9346\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0577 - accuracy: 0.9346\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 793us/step - loss: 0.0575 - accuracy: 0.9346\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0573 - accuracy: 0.9346\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0570 - accuracy: 0.9346\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0568 - accuracy: 0.9346\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0566 - accuracy: 0.9346\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0564 - accuracy: 0.9346\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0562 - accuracy: 0.9346\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0560 - accuracy: 0.9346\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0558 - accuracy: 0.9346\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 627us/step - loss: 0.0557 - accuracy: 0.9346\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0555 - accuracy: 0.9346\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0553 - accuracy: 0.9346\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0552 - accuracy: 0.9346\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0550 - accuracy: 0.9346\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0549 - accuracy: 0.9346\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0547 - accuracy: 0.9346\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0545 - accuracy: 0.9346\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0544 - accuracy: 0.9346\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0542 - accuracy: 0.9346\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 742us/step - loss: 0.0541 - accuracy: 0.9346\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0539 - accuracy: 0.9346\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0538 - accuracy: 0.9346\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0537 - accuracy: 0.9346\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 690us/step - loss: 0.0536 - accuracy: 0.9346\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0535 - accuracy: 0.9346\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0533 - accuracy: 0.9346\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0532 - accuracy: 0.9346\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 627us/step - loss: 0.0531 - accuracy: 0.9346\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0530 - accuracy: 0.9346\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0529 - accuracy: 0.9346\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 690us/step - loss: 0.0528 - accuracy: 0.9346\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0527 - accuracy: 0.9346\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 716us/step - loss: 0.0526 - accuracy: 0.9346\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0525 - accuracy: 0.9346\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 639us/step - loss: 0.0524 - accuracy: 0.9346\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0522 - accuracy: 0.9346\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0522 - accuracy: 0.9346\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0520 - accuracy: 0.9346\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0519 - accuracy: 0.9346\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0518 - accuracy: 0.9346\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0517 - accuracy: 0.9346\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0516 - accuracy: 0.9346\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.0515 - accuracy: 0.9346\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0514 - accuracy: 0.9346\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0513 - accuracy: 0.9346\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0512 - accuracy: 0.9346\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 614us/step - loss: 0.0511 - accuracy: 0.9346\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 665us/step - loss: 0.0510 - accuracy: 0.9346\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0508 - accuracy: 0.9346\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0507 - accuracy: 0.9346\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0506 - accuracy: 0.9346\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0505 - accuracy: 0.9346\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0504 - accuracy: 0.9346\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 639us/step - loss: 0.0503 - accuracy: 0.9346\n"
     ]
    }
   ],
   "source": [
    "fit = ann.fit(X_train, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fit.history['loss'])\n",
    "plt.title('Fitting Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training set'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on the  Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 665us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 588us/step - loss: 0.0502 - accuracy: 0.9346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.050180401653051376, 0.9345570802688599]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for ANN\n",
      "[[  0  22]\n",
      " [  0 292]]\n",
      "\n",
      "Average model prediction accuracy: 92.99%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = (y_pred > 0.5) #Classification metrics can't handle a mix of binary and continuous targets, so we change the target (y_pred) to binary, True/False\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix for ANN\")\n",
    "print(cm)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('\\nAverage model prediction accuracy: {:.2%}\\n'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted model accuracy using the ANN model is 92.99%.  This is slightly higher than the Logistic regression model built in the previous assignment."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing_tools.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166.545px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 357.5,
   "position": {
    "height": "379.5px",
    "left": "1161px",
    "right": "20px",
    "top": "122px",
    "width": "319px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
