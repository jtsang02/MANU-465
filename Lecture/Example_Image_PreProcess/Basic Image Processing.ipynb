{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a887fdb",
   "metadata": {},
   "source": [
    "# Basic Image Analyses as a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01823fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage.measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b380895",
   "metadata": {},
   "source": [
    "## Creat a Matrix of Data Values in Range 0-255\n",
    "0 is balck and 255 is white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb80ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1=[   [255,  255,   255,   255,   255,   255,   255,   255],\n",
    "          [255,  255,   255,   255,   255,   255,   255,   255],\n",
    "          [255,  255,   0,     255,   255,   0,     255,   255],\n",
    "          [255,  255,   255,   255,   255,   255,   255,   255],\n",
    "          [255,  0,     255,   255,   255,   255,   0,     255],\n",
    "          [255,  255,   0,     255,   255,   0,     255,   255],\n",
    "          [255,  255,   255,   0,     0,     255,   255,   255],\n",
    "          [255,  255,   255,   255,   255,   255,   255,   255]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9613a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(Data1, cmap=plt.cm.gray)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d1c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the List to an Array;\n",
    "Data1=np.array(Data1)\n",
    "plt.matshow(Data1, cmap=plt.cm.gray)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching the Black & White, 255-Data\n",
    "plt.matshow(255-Data1, cmap=plt.cm.gray)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed097d",
   "metadata": {},
   "source": [
    "## Color values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try differnt values and check their colors\n",
    "Data2=[[0, 50, 15],\n",
    "       [250, 105, 70],\n",
    "       [41, 90, 237]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(Data2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa368d46",
   "metadata": {},
   "source": [
    "## Plot a CSV File as an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146825dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a csv file\n",
    "MyData=pd.read_csv('SomeData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is just a regular dataset\n",
    "MyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1328dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But, let's plot it, considerign each data point as a pixel value\n",
    "plt.matshow(MyData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a624baec",
   "metadata": {},
   "source": [
    "# Importing the Actual Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd7282",
   "metadata": {},
   "source": [
    "## Import the Image as Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data3 = Image.open('Mosque.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595be9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(Data3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc883b",
   "metadata": {},
   "source": [
    "## Checkign the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aae3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to convert the Image Dataset to an Array\n",
    "ImageArray = np.array(Data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bad476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you see it  3 Matrices of each 547x549; That gives us a RGB image\n",
    "ImageArray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0886a90e",
   "metadata": {},
   "source": [
    "## Checkign Each layer of RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just look at one layer\n",
    "FirstLayer=ImageArray[:,:,0]\n",
    "plt.matshow(FirstLayer)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the other 2 layers \n",
    "SecondLayer=ImageArray[:,:,1]\n",
    "plt.matshow(SecondLayer)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2c3cd",
   "metadata": {},
   "source": [
    "## Save an Image, as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4421cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(FirstLayer)\n",
    "data.to_csv('FirstLayer.csv')\n",
    "\n",
    "# Now, you can cehck your folder to see this file.csv is there; \n",
    "# open the file and take a look. You can do the same for other layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd76050",
   "metadata": {},
   "source": [
    "## Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = Image.open('Ahmad_in_Canyon2.png')\n",
    "ImArray2 = np.array(img2)/1   # you can scale the image values, for example /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a7287",
   "metadata": {},
   "source": [
    "## Image Resizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = img2.resize((400, 300))\n",
    "plt.matshow(new_image)\n",
    "# Note, Resizing, use the average of adjacent pixels; so, as you make the image (here, the dataframe) is smaller, \n",
    "# you are losing some details of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0327e",
   "metadata": {},
   "source": [
    "## Checkign the RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6eef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstLayer1=ImArray2[:,:,0]  # You can check each RGB matrix. The 4th dimension is all zero(only for videos)\n",
    "plt.matshow(FirstLayer1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, the Image of Ahmad in Canyon is just a big matrix (903x1361)\n",
    "pd.DataFrame(FirstLayer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b548362b",
   "metadata": {},
   "source": [
    "## Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = Image.open('Tree.jpg')\n",
    "TreeArr = np.array(Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c142333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(TreeArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ef1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(TreeArr[:,:,2])  # Its second layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a362cba",
   "metadata": {},
   "source": [
    "# Image Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86675ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree2 = np.array(TreeArr)/255   # To Standardize the image Dataset, you just need to scale the image values, \n",
    "# for example divide by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Image will be the same\n",
    "plt.matshow(Tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But, your dataset values are between 0-1\n",
    "pd.DataFrame(Tree2[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f7887",
   "metadata": {},
   "source": [
    "## Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "Woman = Image.open('Woman.jpg')\n",
    "WomanArray = np.array(Woman)   # you can scale the image values, for example /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(WomanArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29acf97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(WomanArray[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29620fa",
   "metadata": {},
   "source": [
    "# Manual Filtering\n",
    "This process is called, Convolution and can be done automatically by Keras. This is just a manual method for convolving an image with a specific Kernel to learn the concepts of Image Filtering by various Kernels. \n",
    "## This Cell creates the Convolution Function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a98bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve2D(image, kernel, padding=0, strides=1):\n",
    "    kernel = np.flipud(np.fliplr(kernel))\n",
    "    xKernShape = kernel.shape[0]\n",
    "    yKernShape = kernel.shape[1]\n",
    "    xImgShape = image.shape[0]\n",
    "    yImgShape = image.shape[1]\n",
    "    xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\n",
    "    yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\n",
    "    output = np.zeros((xOutput, yOutput))\n",
    "    if padding != 0:\n",
    "        imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\n",
    "        imagePadded[int(padding):int(-1 * padding), int(padding):int(-1 * padding)] = image\n",
    "        print(imagePadded)\n",
    "    else:\n",
    "        imagePadded = image\n",
    "\n",
    "    # Iterate through image\n",
    "    for y in range(image.shape[1]):\n",
    "        if y > image.shape[1] - yKernShape:\n",
    "            break\n",
    "        if y % strides == 0:\n",
    "            for x in range(image.shape[0]):\n",
    "                if x > image.shape[0] - xKernShape:\n",
    "                    break\n",
    "                try:\n",
    "                    if x % strides == 0:\n",
    "                        output[x, y] = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]).sum()\n",
    "                except:\n",
    "                    break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85361306",
   "metadata": {},
   "source": [
    "## Try Different Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61936300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can make differnt Kernels as you want, here are a few examples\n",
    "kernel = np.array([[-1, -1, -1], [-1, 4, -1], [-1, -1, -1]])\n",
    "#kernel = np.array([[-1, -1, -1, 1], [-1, 8, -1, 1], [-1, -1, -1, 1],[-1, -1, -1, 1]])\n",
    "#kernel = np.array([[0, 0, 0, 0,0], [0, -2, -1, 0, 0], [0, -1, 1, 1, 0],[0, 0, 1, 2, 0],[0, 0, 0, 0,0]])\n",
    "#kernel = np.array([[0, 0, 0, 0, 0], [0, 0, -1, 0, 0], [0, -1, 50, -1, 0],[0, 0, -1, 0, 0],[0, 0, 0, 0,0]])\n",
    "\n",
    "#kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa937a",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mosque = Image.open('Mosque.jpg')\n",
    "plt.matshow(Data3)\n",
    "MosqueArray = np.array(Mosque)\n",
    "Layer1=MosqueArray[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3506a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = convolve2D(Layer1, kernel, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc78db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(Output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd62c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Differnt Kernels, and see the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d9d32",
   "metadata": {},
   "source": [
    "# More kernels\n",
    "https://en.wikipedia.org/wiki/Kernel_(image_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58d95e",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468cf3c4",
   "metadata": {},
   "source": [
    "<img src='EdgeDetection.jpg' width=1000 height=400/></a>\n",
    "https://www.codingame.com/playgrounds/2524/basic-image-manipulation/filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3579ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_X = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "kernel_Y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "\n",
    "output_X = convolve2D(Layer1, kernel_X, padding=1)\n",
    "output_Y = convolve2D(Layer1, kernel_Y, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f933c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OutputXY=(output_X**2+output_Y**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f08489",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(OutputXY)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55007e7c",
   "metadata": {},
   "source": [
    "## The Woman Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc40bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageData=WomanArray[:,:,0];\n",
    "output_X1 = convolve2D(ImageData, kernel_X, padding=1)\n",
    "output_Y1 = convolve2D(ImageData, kernel_Y, padding=1)\n",
    "\n",
    "OutputXY1=(output_X1**2+output_Y1**2)**0.5\n",
    "\n",
    "plt.matshow(OutputXY1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switchign the Black and White\n",
    "plt.matshow(255-OutputXY1, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63b798",
   "metadata": {},
   "source": [
    "# Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adefd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a demo example\n",
    "\n",
    "a = np.array([\n",
    "      [  20,  200,   -5,   23],\n",
    "      [ -13,  134,  119,  100],\n",
    "      [ 120,   32,   49,   25],\n",
    "      [-120,   12,    9,   23]])\n",
    "skimage.measure.block_reduce(a, (2,2), np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3eccd7",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7eee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try TreeArr[:,:,2]\n",
    "MaxPool=skimage.measure.block_reduce(TreeArr[:,:,2], (2,2), np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(MaxPool)  # Some Details are missed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6d7e8",
   "metadata": {},
   "source": [
    "##### <font color=green> We will continue with CNN next lecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "228px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
